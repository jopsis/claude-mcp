---
title: LangChainì˜ MCP ì–´ëŒ‘í„°
excerpt: LangChain MCP ì–´ëŒ‘í„°ëŠ” MCP ë„êµ¬ë¥¼ LangChain ë° LangGraphì™€ í˜¸í™˜ë˜ê²Œ í•´ì£¼ëŠ” ê²½ëŸ‰ ì–´ëŒ‘í„°ì…ë‹ˆë‹¤.
date: 2025-04-14
slug: langchain-mcp-adapters
coverImage: /images/blog/langchain-mcp-adapters.png
featured: true
author:
  name: ì–‘ë°
  avatar: /images/avatars/yangming.png
category: ê¸°ìˆ 
---

LangChain MCP ì–´ëŒ‘í„° ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” [Anthropic Model Context Protocol (MCP)](/ko) ë„êµ¬ë¥¼ [LangChain](https://github.com/langchain-ai/langchain)ê³¼ [LangGraph](https://github.com/langchain-ai/langgraph)ì™€ í˜¸í™˜ë˜ê²Œ í•´ì£¼ëŠ” ê²½ëŸ‰ ì–´ëŒ‘í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## íŠ¹ì§•

- ğŸ› ï¸ MCP ë„êµ¬ë¥¼ [LangChain ë„êµ¬](https://python.langchain.com/docs/concepts/tools/)ë¡œ ë³€í™˜í•˜ì—¬ [LangGraph](https://github.com/langchain-ai/langgraph) ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥
- ğŸ“¦ ì—¬ëŸ¬ MCP ì„œë²„ì— ì—°ê²°í•˜ê³  í•´ë‹¹ ì„œë²„ì—ì„œ ë„êµ¬ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆëŠ” í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

## ì„¤ì¹˜

```bash
pip install langchain-mcp-adapters
```

`uv` íŒ¨í‚¤ì§€ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
uv add langchain-mcp-adapters langgraph langchain-openai
```

## ë¹ ë¥¸ ì‹œì‘

ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

ë¨¼ì € OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
export OPENAI_API_KEY=<your_api_key>
# í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš° ì´ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.
export OPENAI_API_BASE=<your_api_base>
```

### ì„œë²„

ì˜ˆë¥¼ ë“¤ì–´ ë”í•˜ê¸°ì™€ ê³±í•˜ê¸° ìˆ«ìë¥¼ í•  ìˆ˜ ìˆëŠ” MCP ì„œë²„ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
# math_server.py
from fastmcp import FastMCP

mcp = FastMCP("Math Server")

@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two integers"""
    return a + b

@mcp.tool()
def mul(a: int, b: int) -> int:
    """Multiply two integers"""
    return a * b

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

### í´ë¼ì´ì–¸íŠ¸

ë‹¤ìŒìœ¼ë¡œ, MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LangGraph ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì‘ì—…í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
# client_demo.py
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import asyncio

from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent

from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o")

server_params = StdioServerParameters(
    command="python",
    # math_server.py ì˜ ì „ì²´ ì ˆëŒ€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.
    args=["/your/path/to/math_server.py"],
)

async def main():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # ì´ˆê¸°í™” ì—°ê²°
            await session.initialize()

            # ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
            tools = await load_mcp_tools(session)
            print(f"tools: {tools}")
            # ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰
            agent = create_react_agent(model, tools)
            agent_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})

            # ëª¨ë“  ë©”ì‹œì§€ ì¶œë ¥
            print("All messages:")
            for message in agent_response["messages"]:
                print(f"Message type: {type(message).__name__}")
                print(f"Message content: {message.content}")
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    print(f"Tool calls: {message.tool_calls}")
                if hasattr(message, 'name') and message.name:
                    print(f"Tool name: {message.name}")
                if hasattr(message, 'tool_call_id') and message.tool_call_id:
                    print(f"Tool call id: {message.tool_call_id}")
                print("-" * 50)

if __name__ == "__main__":
    asyncio.run(main())
```

ìœ„ ì½”ë“œì—ì„œëŠ” `langchain_mcp_adapters.tools` ëª¨ë“ˆì˜ `load_mcp_tools` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ MCP ë„êµ¬ë¥¼ ë¡œë“œí•˜ê³ , ì´ í•¨ìˆ˜ëŠ” MCP ë„êµ¬ë¥¼ LangChain ë„êµ¬ë¡œ ìë™ ë³€í™˜í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì´í›„ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì´ëŸ¬í•œ ë„êµ¬ë¥¼ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
$ python3 client_demo.py
[04/14/25 10:18:04] INFO     Processing request of type ListToolsRequest                                                                               server.py:534
tools: [StructuredTool(name='add', description='Add two integers', args_schema={'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x11244aac0>), StructuredTool(name='mul', description='Multiply two integers', args_schema={'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'mulArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x11244aca0>)]
[04/14/25 10:18:09] INFO     Processing request of type CallToolRequest                                                                                server.py:534
                    INFO     Processing request of type CallToolRequest                                                                                server.py:534
All messages:
Message type: HumanMessage
Message content: what's (3 + 5) x 12?
--------------------------------------------------
Message type: AIMessage
Message content:
Tool calls: [{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_0_c350e878-14fc-4b76-9f54-8e2ad7ec0148', 'type': 'tool_call'}, {'name': 'mul', 'args': {'a': 8, 'b': 12}, 'id': 'call_1_c0d807fb-31c8-43ed-9f7c-d4775e30a256', 'type': 'tool_call'}]
--------------------------------------------------
Message type: ToolMessage
Message content: 8
Tool name: add
Tool call id: call_0_c350e878-14fc-4b76-9f54-8e2ad7ec0148
--------------------------------------------------
Message type: ToolMessage
Message content: 96
Tool name: mul
Tool call id: call_1_c0d807fb-31c8-43ed-9f7c-d4775e30a256
--------------------------------------------------
Message type: AIMessage
Message content: The result of \((3 + 5) \times 12\) is \(96\).
--------------------------------------------------
```

ë§ˆì§€ë§‰ ì¶œë ¥ì—ì„œë„ ë³¼ ìˆ˜ ìˆë“¯ì´, ìš°ë¦¬ì˜ ì—ì´ì „íŠ¸ê°€ MCP ë„êµ¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œí•˜ê³  ì˜¬ë°”ë¥¸ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

## ì—¬ëŸ¬ ê°œì˜ MCP ì„œë²„

ì´ MCP ì–´ëŒ‘í„°ëŠ” ì—¬ëŸ¬ ê°œì˜ MCP ì„œë²„ì— ì—°ê²°í•˜ê³  í•´ë‹¹ ì„œë²„ì—ì„œ ë„êµ¬ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤.

### ì„œë²„

ìœ„ì—ì„œ ì´ë¯¸ MCP ì„œë²„ë¥¼ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ, ì´ì œ `weather_server.py` ì˜ MCP ì„œë²„ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
# weather_server.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Weather")

@mcp.tool()
async def get_weather(location: str) -> str:
    """Get weather for location."""
    # mock
    return f"It's always sunny in {location}"


if __name__ == "__main__":
    mcp.run(transport="sse")
```

ì—¬ê¸°ì„œëŠ” `sse` ì „ì†¡ í”„ë¡œí† ì½œì„ ì‚¬ìš©í•˜ê³ , ì´ì œ ì´ MCP ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
$python weather_server.py
INFO:     Started server process [64550]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

### í´ë¼ì´ì–¸íŠ¸

ì´ì œ `client_demo_multi_server.py` ì˜ í´ë¼ì´ì–¸íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
# client_demo_multi_server.py
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
import asyncio

model = ChatOpenAI(model="deepseek-chat")


async def main():
    async with MultiServerMCPClient(
        {
            "math": {
                "command": "python",
                # math_server.py ì˜ ì „ì²´ ì ˆëŒ€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.
                "args": ["/your/path/to/math_server.py"],
                "transport": "stdio",
            },
            "weather": {
                # weather_server.py ì—ì„œ ì‹œì‘í•˜ì„¸ìš”.
                "url": "http://localhost:8000/sse",
                "transport": "sse",
            }
        }
    ) as client:
        agent = create_react_agent(model, client.get_tools())

        math_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})
        weather_response = await agent.ainvoke({"messages": "what is the weather in chengdu?"})

        for message in math_response["messages"]:
            print(f"Math Message type: {type(message).__name__}")
            print(f"Math Message content: {message.content}")
            if hasattr(message, 'tool_calls') and message.tool_calls:
                print(f"Math Tool calls: {message.tool_calls}")
            if hasattr(message, 'name') and message.name:
                print(f"Math Tool name: {message.name}")
            if hasattr(message, 'tool_call_id') and message.tool_call_id:
                print(f"Math Tool call id: {message.tool_call_id}")
            print("-" * 50)
        print("*" * 50)
        for message in weather_response["messages"]:
            print(f"Weather Message type: {type(message).__name__}")
            print(f"Weather Message content: {message.content}")
            if hasattr(message, 'tool_calls') and message.tool_calls:
                print(f"Weather Tool calls: {message.tool_calls}")
            if hasattr(message, 'name') and message.name:
                print(f"Weather Tool name: {message.name}")
            if hasattr(message, 'tool_call_id') and message.tool_call_id:
                print(f"Weather Tool call id: {message.tool_call_id}")
            print("-" * 50)


if __name__ == "__main__":
    asyncio.run(main())

```

ìœ„ ì½”ë“œì—ì„œëŠ” MCP ì–´ëŒ‘í„°ì˜ `MultiServerMCPClient` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ë‹¤ë¥¸ MCP ì„œë²„ë¥¼ ì „ë‹¬í•˜ê³ , ì´ í´ë˜ìŠ¤ëŠ” ì—¬ëŸ¬ ê°œì˜ MCP ì„œë²„ì— ì—°ê²°í•˜ê³  í•´ë‹¹ ì„œë²„ì—ì„œ ë„êµ¬ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤. ì´ì œ ì´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
$python3 client_demo_multi_server.py
[04/14/25 10:32:45] INFO     Processing request of type ListToolsRequest                                server.py:534
[04/14/25 10:32:52] INFO     Processing request of type CallToolRequest                                 server.py:534
                    INFO     Processing request of type CallToolRequest                                 server.py:534
Math Message type: HumanMessage
Math Message content: what's (3 + 5) x 12?
--------------------------------------------------
Math Message type: AIMessage
Math Message content:
Math Tool calls: [{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_0_e6994441-0520-4840-a711-552f78f82e57', 'type': 'tool_call'}, {'name': 'mul', 'args': {'a': 12, 'b': 8}, 'id': 'call_1_d7e9a0d9-ba99-4f07-b583-6f554ee6fecc', 'type': 'tool_call'}]
--------------------------------------------------
Math Message type: ToolMessage
Math Message content: 8
Math Tool name: add
Math Tool call id: call_0_e6994441-0520-4840-a711-552f78f82e57
--------------------------------------------------
Math Message type: ToolMessage
Math Message content: 96
Math Tool name: mul
Math Tool call id: call_1_d7e9a0d9-ba99-4f07-b583-6f554ee6fecc
--------------------------------------------------
Math Message type: AIMessage
Math Message content: The result of \((3 + 5) \times 12\) is \(96\).
--------------------------------------------------
**************************************************
Weather Message type: HumanMessage
Weather Message content: what is the weather in chengdu?
--------------------------------------------------
Weather Message type: AIMessage
Weather Message content:
Weather Tool calls: [{'name': 'get_weather', 'args': {'location': 'chengdu'}, 'id': 'call_0_dbabcd6c-39a6-4d39-8509-8763e7792f77', 'type': 'tool_call'}]
--------------------------------------------------
Weather Message type: ToolMessage
Weather Message content: It's always sunny in chengdu
Weather Tool name: get_weather
Weather Tool call id: call_0_dbabcd6c-39a6-4d39-8509-8763e7792f77
--------------------------------------------------
Weather Message type: AIMessage
Weather Message content: The weather in Chengdu is
```

ìœ„ ì¶œë ¥ì—ì„œë„ ë³¼ ìˆ˜ ìˆë“¯ì´, ìš°ë¦¬ì˜ ì—ì´ì „íŠ¸ê°€ ë‘ ê°œì˜ ë‹¤ë¥¸ MCP ì„œë²„ë¥¼ ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œí•˜ê³  ì˜¬ë°”ë¥¸ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

## LangGraph API ì„œë²„ì—ì„œ ì‚¬ìš©

> [!TIP] > [ì´ ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/) ë¥¼ í™•ì¸í•˜ì—¬ LangGraph API ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”.

ë§Œì•½ ë‹¹ì‹ ì´ LangGraph API ì„œë²„ì—ì„œ MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì„¤ì •ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# graph.py
from contextlib import asynccontextmanager
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic

model = ChatAnthropic(model="claude-3-5-sonnet-latest")

@asynccontextmanager
async def make_graph():
    async with MultiServerMCPClient(
        {
            "math": {
                "command": "python",
                # math_server.py ì˜ ì „ì²´ ì ˆëŒ€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.
                "args": ["/path/to/math_server.py"],
                "transport": "stdio",
            },
            "weather": {
                # weather_server.py ì—ì„œ ì‹œì‘í•˜ì„¸ìš”.
                "url": "http://localhost:8000/sse",
                "transport": "sse",
            }
        }
    ) as client:
        agent = create_react_agent(model, client.get_tools())
        yield agent
```

[`langgraph.json`](https://langchain-ai.github.io/langgraph/cloud/reference/cli/#configuration-file) ì—ì„œ `make_graph` ì„ ì§€ì •í•˜ì„¸ìš”.

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./graph.py:make_graph"
  }
}
```

## ìš”ì•½

LangChain MCP ì–´ëŒ‘í„°ëŠ” MCP ë„êµ¬ë¥¼ LangChain ë° LangGraphì™€ í˜¸í™˜ë˜ê²Œ í•´ì£¼ëŠ” ê²½ëŸ‰ ì–´ëŒ‘í„°ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ê°œì˜ MCP ì„œë²„ì— ì—°ê²°í•˜ê³  í•´ë‹¹ ì„œë²„ì—ì„œ ë„êµ¬ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•˜ë©°, ì´ëŸ¬í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LangGraph ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì‘ì—…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” LangChain ë° LangGraphì—ì„œ MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì„ê³„ê°’ì„ í¬ê²Œ ë‚®ì¶”ì–´ ë” ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [LangChain MCP ì–´ëŒ‘í„°](https://github.com/langchain-ai/langchain-mcp-adapters)
- [LangGraph API ì„œë²„](https://langchain-ai.github.io/langgraph/cloud/reference/cli/#configuration-file)
